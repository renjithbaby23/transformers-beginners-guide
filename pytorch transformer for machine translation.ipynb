{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78d4d79c",
   "metadata": {},
   "source": [
    "Reference: https://www.youtube.com/watch?v=M6adRGJe5cQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82123c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import spacy\n",
    "from utils import translate_sentence, bleu, save_checkpoint, load_checkpoint\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47813b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "spacy_eng = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41077598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ger(text):\n",
    "    return [tok.text for tok in spacy_ger.tokenizer(text)]\n",
    "\n",
    "def tokenize_eng(text):\n",
    "    return [tok.text for tok in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd8bec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "english = Field(tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "246627a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".de\", \".en\"), fields=(german, english)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e65163",
   "metadata": {},
   "outputs": [],
   "source": [
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "995e0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embedding_size,\n",
    "                 src_vocab_size,\n",
    "                 trg_vocab_size,\n",
    "                 src_pad_idx,\n",
    "                 num_heads,\n",
    "                 num_encoder_layers,\n",
    "                 num_decoder_layers,\n",
    "                 forward_expansion,\n",
    "                 dropout,\n",
    "                 max_len,\n",
    "                 device,\n",
    "                ):\n",
    "        super(Transformer, self).__init__()\n",
    "        \n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)     \n",
    "        self.device = device\n",
    "        \n",
    "        self.transformer = nn.Transformer(embedding_size,\n",
    "                                         num_heads,\n",
    "                                         num_encoder_layers,\n",
    "                                         num_decoder_layers,\n",
    "                                         forward_expansion,\n",
    "                                         dropout)\n",
    "        \n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "        return src_mask.to(self.device)\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        src_seq_len, N = src.shape\n",
    "        trg_seq_len, N = trg.shape\n",
    "        \n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_len).unsqueeze(1).expand(src_seq_len, N).to(self.device)\n",
    "        )\n",
    "        \n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_len).unsqueeze(1).expand(trg_seq_len, N).to(self.device)\n",
    "        )\n",
    "        \n",
    "        embd_src = self.dropout(\n",
    "            self.src_word_embedding(src) + self.src_position_embedding(src_positions)\n",
    "        )\n",
    "        \n",
    "        embd_trg = self.dropout(\n",
    "            self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions)\n",
    "        )\n",
    "        \n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_len).to(self.device)\n",
    "        \n",
    "        out = self.transformer(embd_src,\n",
    "                              embd_trg,\n",
    "                              src_key_padding_mask=src_padding_mask,\n",
    "                              tgt_mask=trg_mask)\n",
    "        \n",
    "        out = self.fc_out(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e356a3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the training phase\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "load_model = False\n",
    "save_model = True\n",
    "\n",
    "\n",
    "# Training hyperparameters\n",
    "\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-5\n",
    "batch_size = 32\n",
    "\n",
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "\n",
    "dropout = 0.10\n",
    "max_len = 100\n",
    "forward_expansion = 256\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90fae8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "\n",
    "writer = SummaryWriter('runs/loss_plot')\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13690b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b320960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fccb034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93c9d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, factor=0.1, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbc2bb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('mycheckpoint.pth.tar'), model, optimizer)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6510cdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\n",
    "    \"ein boot mit mehreren männern darauf wird von einem großen\"\n",
    "    \"pferdegespann ans ufer gezogen.\"\n",
    ")\n",
    "\n",
    "sentence = \"ein pferd geht unter einer brücke neben einem boot.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a1a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0 / 5]\n",
      "=> Saving checkpoint\n",
      "Translated example sentence: \n",
      " ['cellphone', 'harmonica', 'dog', 'harmonica', 'steeplechase', 'painting', 'belts', 'belts', 'painting', 'squash', 'driveway', 'harmonica', 'aiming', 'jogs', 'countryside', 'belts', 'painting', 'painting', 'painting', 'belts', 'kitten', 'countryside', 'pain', 'against', 'kitten', 'painting', 'harmonica', 'painting', 'countryside', 'tape', 'golfer', 'kitten', 'kitten', 'steeplechase', 'kitten', 'kitten', 'countryside', 'transporting', 'steeplechase', 'kitten', 'countryside', 'pain', 'transporting', 'ford', 'kitten', 'harmonica', 'steeplechase', 'glacier', 'golfer', 'golfer']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
    "\n",
    "    if save_model:\n",
    "        checkpoint = {\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "        }\n",
    "        save_checkpoint(checkpoint)\n",
    "\n",
    "    model.eval()\n",
    "    translated_sentence = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=50\n",
    "    )\n",
    "\n",
    "    print(f\"Translated example sentence: \\n {translated_sentence}\")\n",
    "    model.train()\n",
    "    losses = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_iterator):\n",
    "        # Get input and targets and get to cuda\n",
    "        inp_data = batch.src.to(device)\n",
    "        target = batch.trg.to(device)\n",
    "\n",
    "        # Forward prop\n",
    "        output = model(inp_data, target[:-1, :])\n",
    "\n",
    "        # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n",
    "        # doesn't take input in that form. For example if we have MNIST we want to have\n",
    "        # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n",
    "        # way that we have output_words * batch_size that we want to send in into\n",
    "        # our cost function, so we need to do some reshapin.\n",
    "        # Let's also remove the start token while we're at it\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        # Clip to avoid exploding gradient issues, makes sure grads are\n",
    "        # within a healthy range\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "        # Gradient descent step\n",
    "        optimizer.step()\n",
    "\n",
    "        # plot to tensorboard\n",
    "        writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
    "        step += 1\n",
    "\n",
    "    mean_loss = sum(losses) / len(losses)\n",
    "    scheduler.step(mean_loss)\n",
    "\n",
    "# running on entire test data takes a while\n",
    "score = bleu(test_data[1:100], model, german, english, device)\n",
    "print(f\"Bleu score {score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116eeca2",
   "metadata": {},
   "source": [
    "### Sample translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = (\n",
    "    \"ein boot mit mehreren männern darauf wird von einem großen\"\n",
    "    \"pferdegespann ans ufer gezogen.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2e5993",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "# Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "if type(sentence) == str:\n",
    "    tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "else:\n",
    "    tokens = [token.lower() for token in sentence]\n",
    "\n",
    "# Add <SOS> and <EOS> in beginning and end respectively\n",
    "tokens.insert(0, german.init_token)\n",
    "tokens.append(german.eos_token)\n",
    "\n",
    "# Go through each german token and convert to an index\n",
    "text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "# Convert to Tensor\n",
    "sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "for i in range(max_len):\n",
    "    trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(sentence_tensor, trg_tensor)\n",
    "    best_guess = output.argmax(2)[-1, :].item()\n",
    "    outputs.append(best_guess)\n",
    "\n",
    "    if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "        break\n",
    "\n",
    "translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "# remove start token\n",
    "\n",
    "print(translated_sentence[1:-1].join(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acc0609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-1.12",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
